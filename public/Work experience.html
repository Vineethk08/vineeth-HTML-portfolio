<!-- This is one possible solution -->
<h1>Professional Experience:</h1>
  <p>
    <h2></h2>Client: Magtech consulting and solutions Development corp.	            June 2023– December 2023<br>
<h3>AWS cloud Engineer</h3> <p></p><h2></h2>

<p></p>•	Build and configure a virtual data center in AWS, including RDS, S3, EC2, Route 53, and IAM, to support Enterprise Data Warehouse hosting. Implemented Security Groups and Route Tables, and configured VPC public and private subnets and Elastic Load Balancer.Configuring and Networking of Virtual Private Cloud (VPC), public subnet and private subnet and route out the private subnet using NAT Gateway.
<p></p>•	Designed roles and groups for users and resources using AWS Identity Access Management (IAM) and implemented Multi-Factor Authentication (MFA) on externally available servers and on AWS Console, Monitoring and alerting leveraging Cloud Watch and Cloud Trail. 
<p></p>•	Enhanced system automation and public cloud deployments using Python and PowerShell scripting to refactor existing scripts and migrate them to Redwood. Configured Terraform scripts for AWS services including Compute, Storage, and Networking, ensuring robust data governance and security integration strategies.
<p></p>•	Creating Dockerfile to manage customized containers, exposing a container with port redirect, container volume management, docker inspect, docker commit to capture the file changes/settings into a new image and pushing the image to docker hub. 
<p></p>•	Configured and deployed Kubernetes clusters to support scalable microservices architecture, utilizing Ansible for automation and aligning with Agile practices for enhanced operational efficiency in Linux environments.
<p></p>•	Configuring Jenkins as a common CI engine to build and promote applications to Dev, QA and Staging to Linux environments.
<p></p>•	Developed and maintained infrastructure as code using Terraform, ensuring consistent and scalable deployments across multiple environments. 
<p></p>•	Orchestrated CI/CD workflows using Jenkins and Groovy-based pipelines, enhancing release process efficiency and integrating Agile methodology to align with modern design patterns.
<p></p>•	Implemented and managed containerized environments using ECS and EKS, optimizing resource utilization and scalability for microservices architecture.
<p></p>•	Provided technical support and troubleshooting for production incidents, ensuring timely resolution and minimal downtime. 
<p></p>•	Implemented DataDog for monitoring and logging across multiple environments, significantly improving system reliability and performance.
<p></p>•	Created scripts in Python which integrated with Amazon API to control instance operations.

<p></p>•	Environment: AWS, Kubernetes, Terraform, Maven, Splunk, Ansible, GitHub, Jira, Data Dog Docker, Kubernetes, IAM, Bash shell, Linux.


<p></p>Client: Sacred Heart University	January 2022– march 2023
<p></p>Graduate Student Assistant (cloud)

<p></p>•	As a graduate student assistant, I helped my professor with teaching responsibilities. This include preparing course materials, grading assignments or exams, leading discussion sections, or even delivering guest lectures on topics related to Cloud computing. 
<p></p>•	provided technical support to students and colleagues who are working on projects or assignments involving Cloud computing. This involve troubleshooting issues with cloud services, helping set up development environments and providing guidance on best practices for cloud-based application development. 
<p></p>•	participated in conferences, workshops, or seminars related to Cloud computing. This involve presenting research findings, networking with other researchers in the field and participating in panel discussions on emerging trends or technologies in Cloud computing.


<p></p>Client:FINETECH	August 2018– December 2021
<p></p>AWS Cloud/Devops Engineer 

<p></p>•	Optimized EBS volumes and EC2 instances, created multi Availability Zone VPC instances, and maintained traffic using Route 53 Weight Routing Policies. Utilized AWS SNS for notifications and implemented credential management with AWS Secret Manager.
<p></p>•	Developed and migrated Python scripts to automate AWS data services, focusing on cloud migration and database optimization with MySQL and Aurora. Utilized AWS CloudWatch for monitoring and integrated AWS Key Management Service (KMS) for enhanced security.
<p></p>•	Used security groups, network ACLs, Internet Gateways, NAT instances, and Route tables to ensure a secure zone for organizations in AWS public cloud. 
<p></p>•	Implemented RESTful web services using Java Spring framework deployed on AWS Lambda, achieving serverless architecture for cost-effective and scalable solutions.
<p></p>•	Written Terraform templates and Chef cookbooks and pushed them onto Chef for configuring EC2 Instance. Solved Gateway time issue on ELB and moved all the logs to S3 Bucket using Terraform.
<p></p>•	Developed Lambda functions in Python to automate data streaming, ETL processes, and database operations MySQL, RDS, Aurora on AWS, optimizing data and cloud migration strategies with enhanced observability using Amazon CloudWatch.
<p></p>•	Demonstrated strong problem-solving abilities and customer service skills to address issues promptly and efficiently.
<p></p>•	Responsible for installing Jenkins master and slave nodes and configuring Jenkins builds for continuous integration and delivery. Set up and Configured Jenkins for application deployment.  
<p></p>•	Enhanced automation of build and deployment processes using Bash and Python scripts, integrating CI/CD tools like Jenkins and GitLab, fostering a robust DevOps culture under Agile methodologies.
<p></p>•	Led incident response efforts, utilizing DataDog to troubleshoot and resolve issues swiftly, improving system uptime. 
<p></p>•	Automated Datadog Dashboards and assisted internal users for Splunk in designing and maintaining production-quality dashboards. 

 
<p></p>Environment: AWS, OpenStack, OpenShift, Git, Maven, Jenkins, Linux, Jira, Chef, Ansible, Docker, Data Dog, Splunk, Python, EC2, S3, EBS, ELB, Opswork, Splunk. Mac OS. 


<p></p>Internship: IIT Roorke
<p></p>Platform engineer									FEBRUARY 2018- APRIL 2018						
<p></p>In this project, we aim to build an end-to-end CI/CD pipeline for a Kubernetes application using AWS Cloud for Drone CI. The pipeline will encompass the following key stages: source code management, automated testing, containerization, and deployment to a Kubernetes cluster. The goal is to achieve seamless integration and continuous delivery while leveraging the power of Kubernetes for orchestrating containerized applications.

<p></p>Key Components and Tasks:
<p></p>•	Setting up a version control system Git to manage the application source code.
<p></p>•	Configured Drone CI to connect with the version control system for automated triggering of CI/CD workflows.
<p></p>•	Implemented and automated testing scripts using testing frameworks suitable for your application (e.g., JUnit for Java, Pytest for Python).
<p></p>•	Configured Drone CI to run these tests automatically upon each code commit.
<p></p>•	Containerize the application using Docker.
<p></p>•	Implemented a Dockerfile to define the application's dependencies and build the Docker image.
<p></p>•	Configured Drone CI to build and push the Docker image to a container registry (e.g., Docker Hub).
<p></p>•	Setting up a Kubernetes cluster (locally using tools like Minikube in the cloud using managed services).
<p></p>•	Defined Kubernetes manifests (YAML files) for deploying the application, including services, deployments, and any required configurations.
<p></p>•	Integrated Drone CI with Kubernetes to automate the deployment process.
<p></p>•	Implemented secure handling of secrets and sensitive configuration data.
<p></p>•	Leveraged Drone CI's secret management capabilities to securely store and access sensitive information.
<p></p>•	Integrated monitoring and logging solutions suitable for Kubernetes like Prometheus, Grafana, ELK stack.
<p></p>•	Configured Drone CI to provide visibility into CI/CD pipeline execution.
<p></p>•	Defined the CI/CD pipeline using Drone CI's configuration files (drone.yml) as code.
<p></p>•	Implemented stages for linting, testing, building, and deploying the application.
<p></p>•	I am implementing caching strategies for dependencies to further enhance pipeline performance.

<p></p>Outcome:
<p>Upon completion of the project, I have a fully functional CI/CD pipeline orchestrated by Drone CI for a Kubernetes-based application. The pipeline will automate testing, containerization, and deployment processes, promoting a streamlined and efficient development workflow within a Kubernetes-centric DevOps environment.

